{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8avrFMwELRe"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install python-decouple\n",
        "!pip install youtube_transcript_api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQdUxPq7KjBV"
      },
      "outputs": [],
      "source": [
        "!pip install scrapingbee\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3Je24shKect"
      },
      "outputs": [],
      "source": [
        "from scrapingbee import ScrapingBeeClient\n",
        "import os\n",
        "import openai\n",
        "import json\n",
        "import re\n",
        "!pip install scrapingbee-sdk openai\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8EXD032iET4g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import json\n",
        "import re\n",
        "from time import time, sleep\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import textwrap\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api.formatters import TextFormatter\n",
        "# # from decouple import config   # this is usually enough to read configs in non-notebook environment\n",
        "# import decouple\n",
        "# config = decouple.AutoConfig('.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gqG-O5BzKWI9"
      },
      "outputs": [],
      "source": [
        "bee_key = ''\n",
        "openai_key = ''\n",
        "\n",
        "client = ScrapingBeeClient(api_key=bee_key)\n",
        "openai.api_key = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gpw0MbeaEkoO"
      },
      "outputs": [],
      "source": [
        "def get_transcript(url):\n",
        "    url_data = urlparse(url)\n",
        "    video_id = parse_qs(url_data.query)[\"v\"][0]\n",
        "    if not video_id:\n",
        "        print('Video ID not found.')\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        formatter = TextFormatter()\n",
        "\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
        "        text = formatter.format_transcript(transcript)\n",
        "        text = re.sub('\\s+', ' ', text).replace('--', '')\n",
        "        return video_id, text\n",
        "\n",
        "    except Exception as e:\n",
        "        print('Error downloading transcript:', e)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "T50Qmfz3En8R"
      },
      "outputs": [],
      "source": [
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "\n",
        "def save_file(content, filepath):\n",
        "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CrDUwrG8ErS4"
      },
      "outputs": [],
      "source": [
        "def gpt3_completion(prompt, model='text-davinci-003', temp=0.5, top_p=1.0, tokens=500, freq_pen=0.25, pres_pen=0.0, stop=['\\n']):\n",
        "    max_retry = 3\n",
        "    retry = 0\n",
        "    while True:\n",
        "        try:\n",
        "            response = openai.Completion.create(\n",
        "                model=model,\n",
        "                prompt=prompt,\n",
        "                temperature=temp,\n",
        "                max_tokens=tokens,\n",
        "                top_p=top_p,\n",
        "                frequency_penalty=freq_pen,\n",
        "                presence_penalty=pres_pen,\n",
        "                stop=stop)\n",
        "            text = response['choices'][0]['text'].strip()\n",
        "            text = re.sub('\\s+', ' ', text)\n",
        "            if not text:\n",
        "                retry += 1\n",
        "                continue\n",
        "            filename = f'gpt3_{time()}.log'\n",
        "            with open(f'gpt3_logs/{filename}', 'w') as outfile:\n",
        "                outfile.write('PROMPT:\\n\\n' + prompt + '\\n\\n==========\\n\\nRESPONSE:\\n\\n' + text)\n",
        "            return text\n",
        "\n",
        "        except Exception as e:\n",
        "            retry += 1\n",
        "            if retry >= max_retry:\n",
        "                return \"GPT3 error: %s\" % e\n",
        "            print('Error communicating with OpenAI:', e)\n",
        "            sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_bmnz8ZzEuvk"
      },
      "outputs": [],
      "source": [
        "def ask_gpt(text, prompt_file, output_file, job='SUMMARY'):\n",
        "    # Summarize chunks\n",
        "    chunks = textwrap.wrap(text, width=10000)\n",
        "    results = list()\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        prompt = open_file(prompt_file).replace('<<CONTENT>>', chunk)\n",
        "        prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
        "        output = ''\n",
        "        if job=='SUMMARY':\n",
        "            output = gpt3_completion(prompt, tokens=500)\n",
        "        elif job == 'REWRITE':\n",
        "            output = gpt3_completion(prompt, tokens=2048)\n",
        "        results.append(output)\n",
        "        print(f'{i+1} of {len(chunks)}\\n{output}\\n\\n\\n')\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B6MlmFU_t_HN"
      },
      "outputs": [],
      "source": [
        "!mkdir -p gpt3_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhqbXaZLEydV"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.youtube.com/watch?v=kfTVbJb9yIE'\n",
        "\n",
        "# Download transcript\n",
        "video_id, text = get_transcript(url)\n",
        "\n",
        "# Summarize the transcript (chunk by chunk if needed)\n",
        "if text:\n",
        "    # Summarize transcript\n",
        "    output_file = f'summary_{video_id}_{time()}.txt'\n",
        "    results = ask_gpt(text, 'prompt_summary.txt', 'SUMMARY')\n",
        "    summary = '\\n\\n'.join(results)\n",
        "    save_file(summary, output_file)\n",
        "\n",
        "    # Summarize the summary\n",
        "    if len(results) > 1:\n",
        "        new_summary = ask_gpt(summary, 'prompt_rewrite.txt', 'REWRITE')\n",
        "        save_file('\\n\\n'.join(new_summary), output_file.replace('.txt', '_2.txt'))\n",
        "\n",
        "    print('----- Mission Complete -----')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
